# Multilabel-toxicity-classification-challenge

## This Project aimed at building a multi-label classifier for comments text in online comments dataset (as part of Jigsaw Toxic Comment Classification Challenge : https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)


In this Project I experimented with various NLP based classifiers and used Softmax thresholds to identify one of many toxic attributes in text (toxic, severe_toxic, obscene, threat, insult, identity_hate).
I Built various models to benchmark on Vanilla RNN, LSTM, GRU and DistilBERT. Also attempted fine tuning OpenAI APIs based GPT-3 models. Achieved best results of 98.3% using GPT-3 (Ada base) fine tuned model.
